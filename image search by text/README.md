# Поиск изображения по текстовому описанию

## Описание проекта

Необходимо разработать демонстрационную версию поиска изображений по запросу.

Требуется обучить модель, которая получит векторное представление изображения, векторное представление текста, а на выходе выдаст число от 0 до 1 — покажет, насколько текст и картинка подходят друг другу.

## Навыки и инструменты

* python
* pandas (plotting.table)
* numpy
* termcolor (colored, cprint)
* matplotlib.pyplot
* seaborn
* io
* os
* PIL.Image
* translate.Translator
* spacy
* re
* math.ceil
* torch (nn)
* torchvision.models (transforms)
* transformers (Bert)
* tqdm.notebook
* sklearn (GroupShuffleSplit, LinearRegression, Ridge, mean_absolute_error)

## Вывод

Модель по подбору изображения на основе текстового описания может быть изготовлена с учётом некоторых дороботок относительно сделанного PoC (Proof of Concept).

* Необходимо улучшить качество работы модели за счёт:\
\* расширения пула картинок, на которых обучалась модель; в том числе за счёт аугментации положительных примеров;\
\* поэксперементировать с другими предобученными моделями для создания эмбеддингов;\
\* попробовать подобрать более оптимальную архитектуру нейроной сети для обучения.
* Выдавать на запрос не одно изображение, а 10. Вероятность нахождения пользователем нужной картинки значительно увеличится.

<br>
По сути проведённой работы:
* признаки для обучения моделей подготовлены в виде эмбеддингов с помощью BERT (для текста) и ResNet50 (для изображений);\
полученная длина конкатенированных признаков 1768 (1000 изображение + 768 текст);
* построенные модели: LinearRegression, Ridge, Neural network с различными гиперпараметрами и архитектурой;\
лучший результат у полносвязной нейронной сети; MAE = 0.1288;
* проверка модели на тестовых данных визуально продемонстировала качество работы алгоритма около **34%** (по "мнению" модели вероятность соответсвия подобранных картинок 52%).
